# Итоги проделанной работы

## 1. Что было сделано

- Проведена предобработка данных и базовый EDA: распределение переменных, корреляции.
- Реализованы базовые модели регрессии (LinearRegression, Ridge, Lasso).
- Проведен подбор гиперпараметров с помощью GridSearchCV.
- Реализованы методы отбора признаков (L0 и L1-подходы).
- Создана кастомная метрика, учитывающая, что недопрогноз хуже перепрогноза.

---

## 2 и 3. С какими результатами и что дало наилучший буст

- Простая линейная регрессия с дополнительными переменными (year и year**2) оказалась лучшей моделью.
- Ridge улучшила устойчивость к мультиколлинеарности, но почти не изменила ошибки.
- Lasso обнулила все признаки, но не дала значимого роста качества модели.

---

## 4. Что сделать не вышло и почему

### Полноценная L0-регуляризация
- sklearn **не поддерживает L0 напрямую** (NP-hard задача).
- Корректное решение требует использования более сложных методов.


---

## 5. Выводы

- Лучшая модель - линейная без регуляризации с дополнительными фичами, помимо вещественных.
- Работа с категориальными признаками может значительно повысить качество модели, как случилось с годом. 

